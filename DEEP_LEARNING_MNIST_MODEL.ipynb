{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO3RISCX7x9t1F5FbsStMry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sajeethaprabu/CHAT-ROOM/blob/main/DEEP_LEARNING_MNIST_MODEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sfs8wRxrydG-"
      },
      "outputs": [],
      "source": [
        "\n",
        "sajeetha p\n",
        "12:13â€¯PM (10 hours ago)\n",
        "to me\n",
        "\n",
        "import tensorflow as tf #importing the library tensorflow and namining it as \"tf\"\n",
        "from tensorflow import keras #from tensorflow importing keras for training testing , its a high level deep learning API used in neural network models\n",
        "from tensorflow.keras import layers #from keras importing layers for implementing layers(input,hidden,output)\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data() #imports the MNIST dataset contains 0-9 in 70,000 images with 28 x 28 size | 60,000 images used for training 10,000 images used for testing(90:10 rule)\n",
        "#training =approx(85%)\n",
        "#testing =approx(14%)\n",
        "\n",
        "\n",
        "x_train = x_train / 255.0 #normalizing the data ranges\n",
        "x_test = x_test / 255.0   #normalizing the data ranges\n",
        "\n",
        "\n",
        "model = keras.Sequential([ # sequential == stacked up with many layers (sequence= input -> hidden -> output)\n",
        "\n",
        "    layers.Flatten(input_shape=(28, 28)), #converts images into 1D vector (28 * 28 = 784 neurons)\n",
        "\n",
        "    layers.Dense(128, activation='relu'), #Fully connected hidden layer uses relu(rectified linear unit) to introduce non-linearity f(x) = max(0, x)\n",
        "\n",
        "    layers.Dense(10, activation='softmax') #Output layer which has 10 neurons with the activation function of softmax it converts output into probabilities\n",
        "])\n",
        "\n",
        "model.compile( #compiling\n",
        "    optimizer='adam', #Adam is an advanced gradient descent algorithm. updates weights efficiently.\n",
        "    loss='sparse_categorical_crossentropy', #Lables integer and predicts error\n",
        "    metrics=['accuracy'] #metrics of finding accuracy (NUMBER OF CORRECT PREDICTIONS / NUMBER OF PREDICTIONS)\n",
        ")\n",
        "\n",
        "\n",
        "model.fit(x_train, y_train, epochs=5) #fitting the model with training Runs the complete training process 5 times over the entire dataset\n",
        "test_loss, test_accuracy = model.evaluate(x_test, y_test) # evaluating the model\n",
        "\n",
        "print(\"Test Accuracy:\", test_accuracy) #prints the accuarcy"
      ]
    }
  ]
}